accelerator: ddp
accumulate_grad_batches: 1
adj_mat_path: ./adj_all_65/adj_binary.npy
adj_normalization: Sym
amp_backend: native
amp_level: O2
ann_root: /mnt/data0/qh/Sewer/annotations
args: !!python/object:argparse.Namespace
  accelerator: ddp
  accumulate_grad_batches: 1
  adj_mat_path: ./adj_all_65/adj_binary.npy
  adj_normalization: Sym
  amp_backend: native
  amp_level: O2
  ann_root: /mnt/data0/qh/Sewer/annotations
  auto_lr_find: false
  auto_scale_batch_size: false
  auto_select_gpus: false
  automatic_optimization: null
  backbone: resnet50
  batch_size: 128
  benchmark: false
  bottleneck_channels: null
  check_val_every_n_epoch: 1
  checkpoint_callback: true
  class_weight: Effective
  conda_env: qh
  data_root: /mnt/data0/qh/Sewer
  decoder: CTGNN
  decoder_channels: &id001 []
  decoder_pool: Avg
  default_root_dir: null
  defect_weights: PosCIW
  deterministic: false
  distributed_backend: null
  dwa_temp: 2.0
  effective_beta: 0.9999
  enable_pl_optimizer: null
  encoder: ResNetBackbone
  f2CIW_weights: PosWeight
  fast_dev_run: false
  flush_logs_every_n_steps: 100
  gat_num_heads: 8
  gnn_channels: 128
  gnn_dropout: 0.0
  gnn_head: GCN
  gnn_layers: 4
  gnn_residual: true
  gnn_residual_act: Pre
  gpus: null
  gradient_clip_val: 0
  learning_rate: 0.1
  learning_rate_gamma: 0.01
  learning_rate_steps: &id002
  - 20
  limit_predict_batches: 1.0
  limit_test_batches: 1.0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  log_every_n_steps: 100
  log_gpu_memory: null
  log_save_dir: ./log
  log_version: 1
  logger: true
  lr_schedule: Step
  main_weight: 0.75
  max_epochs: 30
  max_steps: null
  min_epochs: null
  min_steps: null
  momentum: 0.9
  move_metrics_to_cpu: false
  multiple_trainloader_mode: max_size_cycle
  num_nodes: 1
  num_processes: 1
  num_sanity_val_steps: 2
  only_defects: false
  overfit_batches: 0.0
  plugins: null
  precision: 16
  prepare_data_per_node: true
  process_position: 0
  profiler: null
  progress_bar_refresh_rate: 2
  reload_dataloaders_every_epoch: false
  replace_sampler_ddp: true
  resume_from_checkpoint: null
  schedule_int: epoch
  seed: 1234567890
  shared_bottleneck: false
  shared_linear: false
  stochastic_weight_avg: false
  sync_batchnorm: false
  task_weight: Fixed
  task_weights_fixed: &id003
  - 27.0
  - 1.0
  terminate_on_nan: false
  tpu_cores: null
  track_grad_norm: -1
  truncated_bptt_steps: null
  use_auxilliary: true
  use_deterministic: false
  val_check_interval: 1.0
  valid_tasks: &id004
  - defect
  - water
  weight_decay: 0.0001
  weights_learning_rate: 0.025
  weights_save_path: null
  weights_summary: top
  workers: 12
auto_lr_find: false
auto_scale_batch_size: false
auto_select_gpus: false
automatic_optimization: null
backbone: resnet50
batch_size: 128
benchmark: false
bottleneck_channels: null
check_val_every_n_epoch: 1
checkpoint_callback: true
class_weight: Effective
conda_env: qh
data_root: /mnt/data0/qh/Sewer
decoder: CTGNN
decoder_channels: *id001
decoder_pool: Avg
default_root_dir: null
defect_weights: PosCIW
deterministic: false
distributed_backend: null
dwa_temp: 2.0
effective_beta: 0.9999
enable_pl_optimizer: null
encoder: ResNetBackbone
f2CIW_weights: PosWeight
fast_dev_run: false
flush_logs_every_n_steps: 100
gat_num_heads: 8
gnn_channels: 128
gnn_dropout: 0.0
gnn_head: GCN
gnn_layers: 4
gnn_residual: true
gnn_residual_act: Pre
gpus: null
gradient_clip_val: 0
learning_rate: 0.1
learning_rate_gamma: 0.01
learning_rate_steps: *id002
limit_predict_batches: 1.0
limit_test_batches: 1.0
limit_train_batches: 1.0
limit_val_batches: 1.0
log_every_n_steps: 100
log_gpu_memory: null
log_save_dir: ./log
log_version: 1
logger: true
lr_schedule: Step
main_weight: 0.75
max_epochs: 30
max_steps: null
min_epochs: null
min_steps: null
momentum: 0.9
move_metrics_to_cpu: false
multiple_trainloader_mode: max_size_cycle
num_nodes: 1
num_processes: 1
num_sanity_val_steps: 2
only_defects: false
overfit_batches: 0.0
plugins: null
precision: 16
prepare_data_per_node: true
process_position: 0
profiler: null
progress_bar_refresh_rate: 2
reload_dataloaders_every_epoch: false
replace_sampler_ddp: true
resume_from_checkpoint: null
schedule_int: epoch
seed: 1234567890
shared_bottleneck: false
shared_linear: false
stochastic_weight_avg: false
sync_batchnorm: false
task_class_type:
- ML
- MC
task_class_weights:
- - null
  - !!python/object/apply:torch._utils._rebuild_tensor_v2
    - !!python/object/apply:torch.storage._load_from_bytes
      - !!binary |
        gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
        AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
        aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
        Z2UKcQFYDgAAADk0Njc4OTQ5MDM2NDQ4cQJYAwAAAGNwdXEDSxFOdHEEUS6AAl1xAFgOAAAAOTQ2
        Nzg5NDkwMzY0NDhxAWEuEQAAAAAAAAB1VCJAtSWzPwALPD+po9I+LmbQP9Lb7z7GF2c/T01LP6mj
        Uj5guBM/I9YgP8oDaj4nSYc/J0mHPzY+EkDfn3g/cLiOPw==
    - 0
    - !!python/tuple
      - 17
    - !!python/tuple
      - 1
    - false
    - !!python/object/apply:collections.OrderedDict
      - []
- !!python/object/apply:torch._utils._rebuild_tensor_v2
  - !!python/object/apply:torch.storage._load_from_bytes
    - !!binary |
      gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
      AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
      aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
      Z2UKcQFYDgAAADk0Njc0NzEwNTc5MTIwcQJYAwAAAGNwdXEDSwROdHEEUS6AAl1xAFgOAAAAOTQ2
      NzQ3MTA1NzkxMjBxAWEuBAAAAAAAAACS52E/kudhP5uOdT88TqM/
  - 0
  - !!python/tuple
    - 4
  - !!python/tuple
    - 1
  - false
  - !!python/object/apply:collections.OrderedDict
    - []
task_classes:
- 17
- 4
task_criterion_weighting: Fixed
task_weight: Fixed
task_weights_fixed: *id003
terminate_on_nan: false
tpu_cores: null
track_grad_norm: -1
truncated_bptt_steps: null
use_auxilliary: true
use_deterministic: false
val_check_interval: 1.0
valid_tasks: *id004
weight_decay: 0.0001
weights_learning_rate: 0.025
weights_save_path: null
weights_summary: top
workers: 12
